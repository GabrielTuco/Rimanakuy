{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing~=3.6.6 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 1)) (3.6.6)\n",
      "Requirement already satisfied: torchtext~=0.4.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: torch in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: numpy~=1.20 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: sacrebleu~=1.4.2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 6)) (1.4.14)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 7)) (3.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 8)) (4.66.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 9)) (4.42.4)\n",
      "Requirement already satisfied: pandas~=1.5.3 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 10)) (1.5.3)\n",
      "Requirement already satisfied: seaborn~=0.9.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 11)) (0.9.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: oyaml~=0.9 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 13)) (0.9)\n",
      "Requirement already satisfied: umap~=0.1.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 14)) (0.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 15)) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: gensim==4.3.2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 17)) (4.3.2)\n",
      "Requirement already satisfied: sacremoses~=0.0.35 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 18)) (0.0.53)\n",
      "Collecting scipy==1.11.4 (from -r requirements.txt (line 19))\n",
      "  Downloading scipy-1.11.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.4 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 643.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: glob2~=0.6 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 20)) (0.7)\n",
      "Requirement already satisfied: visdom~=0.1.8.9 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 21)) (0.1.8.9)\n",
      "Requirement already satisfied: graphviz in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 22)) (0.20.3)\n",
      "Requirement already satisfied: dill in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 23)) (0.3.8)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from -r requirements.txt (line 24)) (2.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from gensim==4.3.2->-r requirements.txt (line 17)) (7.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torchtext~=0.4.0->-r requirements.txt (line 2)) (2.32.2)\n",
      "Requirement already satisfied: six in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torchtext~=0.4.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (2021.4.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from sacrebleu~=1.4.2->-r requirements.txt (line 6)) (2.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tqdm->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (0.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (0.19.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from pandas~=1.5.3->-r requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 15)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 15)) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from sacremoses~=0.0.35->-r requirements.txt (line 18)) (8.1.7)\n",
      "Requirement already satisfied: tornado in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from visdom~=0.1.8.9->-r requirements.txt (line 21)) (6.4.1)\n",
      "Requirement already satisfied: pyzmq in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from visdom~=0.1.8.9->-r requirements.txt (line 21)) (25.1.2)\n",
      "Requirement already satisfied: jsonpatch in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from visdom~=0.1.8.9->-r requirements.txt (line 21)) (1.33)\n",
      "Requirement already satisfied: torchfile in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from visdom~=0.1.8.9->-r requirements.txt (line 21)) (0.1.0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from visdom~=0.1.8.9->-r requirements.txt (line 21)) (1.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (69.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from tensorboard->-r requirements.txt (line 24)) (3.0.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 3)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 3)) (2021.13.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from smart-open>=1.8.1->gensim==4.3.2->-r requirements.txt (line 17)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 24)) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from jsonpatch->visdom~=0.1.8.9->-r requirements.txt (line 21)) (3.0.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from portalocker->sacrebleu~=1.4.2->-r requirements.txt (line 6)) (305.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests->torchtext~=0.4.0->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests->torchtext~=0.4.0->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests->torchtext~=0.4.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from requests->torchtext~=0.4.0->-r requirements.txt (line 2)) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gabriel\\anaconda3\\envs\\rimanakuy\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Downloading scipy-1.11.4-cp310-cp310-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/44.1 MB 2.6 MB/s eta 0:00:18\n",
      "    --------------------------------------- 0.6/44.1 MB 7.5 MB/s eta 0:00:06\n",
      "    --------------------------------------- 1.0/44.1 MB 9.4 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.4/44.1 MB 8.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 3.1/44.1 MB 5.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.1/44.1 MB 5.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.6/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 4.2/44.1 MB 6.1 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 4.2/44.1 MB 6.1 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 4.2/44.1 MB 6.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.2/44.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.2/44.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 4.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 7.3/44.1 MB 5.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 7.3/44.1 MB 5.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 7.5/44.1 MB 5.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.3/44.1 MB 5.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.4/44.1 MB 5.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.5/44.1 MB 4.6 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 11.5/44.1 MB 4.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 11.5/44.1 MB 4.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 11.5/44.1 MB 4.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 13.2/44.1 MB 4.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 13.6/44.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 13.6/44.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 14.7/44.1 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 14.7/44.1 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 14.7/44.1 MB 4.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 15.7/44.1 MB 4.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 16.8/44.1 MB 4.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 16.8/44.1 MB 4.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 17.8/44.1 MB 4.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 17.8/44.1 MB 4.4 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.9/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.3/44.1 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 21.0/44.1 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.0/44.1 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 22.0/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 22.0/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 22.0/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 22.0/44.1 MB 5.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 23.1/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.1/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.1/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.1/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 23.3/44.1 MB 5.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 24.1/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.1/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.2/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.2/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.2/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 26.2/44.1 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 26.2/44.1 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 26.8/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.4/44.1 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 28.3/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 28.3/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 29.4/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.4/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.6/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.5/44.1 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.5/44.1 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.5/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.5/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.7/44.1 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.6/44.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.6/44.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.6/44.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.6/44.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.6/44.1 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.7/44.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 37.7/44.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 37.7/44.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 38.4/44.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 38.8/44.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 39.1/44.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 39.8/44.1 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 39.8/44.1 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.1/44.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.0\n",
      "    Uninstalling scipy-1.14.0:\n",
      "      Successfully uninstalled scipy-1.14.0\n",
      "Successfully installed scipy-1.11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir LlamaRoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=16SkLOsfja22kIwExs4NiU5pjrOV7SUdP\n",
      "From (redirected): https://drive.google.com/uc?id=16SkLOsfja22kIwExs4NiU5pjrOV7SUdP&confirm=t&uuid=cdc8690b-aba1-4b4e-a0a3-06f938508703\n",
      "To: E:\\Tesis\\Code\\Rimanakuy\\LlamaRoBERTa\\pytorch_model.bin\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 334M/334M [00:20<00:00, 16.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LlamaRoBERTa/pytorch_model.bin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "url = 'https://drive.google.com/uc?id=16SkLOsfja22kIwExs4NiU5pjrOV7SUdP'\n",
    "output = 'LlamaRoBERTa/pytorch_model.bin'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lDaVeJc90TKbBrhxZKZbIfRTPv9VSsOg\n",
      "To: E:\\Tesis\\Code\\Rimanakuy\\LlamaRoBERTa\\config.json\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 676/676 [00:00<00:00, 677kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PrM9LMJ9Pmrc8yqKBT1OMRPXD1urkJ1r\n",
      "To: E:\\Tesis\\Code\\Rimanakuy\\LlamaRoBERTa\\merges.txt\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 483k/483k [00:00<00:00, 1.67MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1i6L13u5P9HVzzmKsNZxe_wICteulIWY5\n",
      "To: E:\\Tesis\\Code\\Rimanakuy\\LlamaRoBERTa\\vocab.json\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 837k/837k [00:00<00:00, 2.29MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LlamaRoBERTa/vocab.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdown.download('https://drive.google.com/uc?id=1lDaVeJc90TKbBrhxZKZbIfRTPv9VSsOg', 'LlamaRoBERTa/config.json', quiet=False)\n",
    "gdown.download('https://drive.google.com/uc?id=1PrM9LMJ9Pmrc8yqKBT1OMRPXD1urkJ1r', 'LlamaRoBERTa/merges.txt', quiet=False)\n",
    "gdown.download('https://drive.google.com/uc?id=1i6L13u5P9HVzzmKsNZxe_wICteulIWY5', 'LlamaRoBERTa/vocab.json', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizer\n",
    "\n",
    "model_name = \"LlamaRoBERTa\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2 = type(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.vocab import Vocab\n",
    "Vocab().from_roberta(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_modules at 0x000002BCC40A1E70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4ErAKf7j1Qs"
   },
   "source": [
    "#LM-prior-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqtSuezV1UQS",
    "outputId": "f8b3f099-71d8-4a0c-e346-1cfbbbc1f509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', 'Asdas')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.split(\"./Asdas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "purwOmGGNBFx",
    "outputId": "3c14ef81-f61f-44b2-ebae-0e0b62753e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:configs/transformer/trans.ques_base.yaml\n",
      "name:final.trans.ques_base\n",
      "desc:None\n",
      "tag:None\n",
      "visdom:False\n",
      "pin_memory:False\n",
      "resume_cp:None\n",
      "resume_state_id:None\n",
      "device:cpu\n",
      "cores:4\n",
      "src_dirs:['E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\models', 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\modules', 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\helpers']\n",
      "\n",
      "{'batch_tokens': 10000,\n",
      " 'config': 'configs/transformer/trans.ques_base.yaml',\n",
      " 'cores': 4,\n",
      " 'data': {'lowercase': True,\n",
      "          'prior_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\LlamaRoBERTa',\n",
      "          'seq_len': 1000,\n",
      "          'sos': True,\n",
      "          'src': {'lang': 'de',\n",
      "                  'subword_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\source',\n",
      "                  'test_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.test',\n",
      "                  'train_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.train',\n",
      "                  'val_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.dev'},\n",
      "          'streaming': False,\n",
      "          'trg': {'lang': 'en',\n",
      "                  'subword_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\target',\n",
      "                  'test_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.test',\n",
      "                  'train_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.train',\n",
      "                  'val_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.dev'},\n",
      "          'vocab_path': None,\n",
      "          'vocab_size': None},\n",
      " 'desc': None,\n",
      " 'device': 'cpu',\n",
      " 'epochs': 2,\n",
      " 'init': {'embed_init': 'xavier_uniform',\n",
      "          'linear_init': 'xavier_uniform',\n",
      "          'lstm_hh_init': 'orthogonal',\n",
      "          'lstm_ih_init': 'xavier_uniform'},\n",
      " 'logging': {'checkpoint_interval': 2,\n",
      "             'emb_inspect_interval': 200,\n",
      "             'eval_interval': 1000,\n",
      "             'full_eval_interval': 4000000,\n",
      "             'log_interval': 50,\n",
      "             'module_grad_interval': 200,\n",
      "             'samples_interval': 200},\n",
      " 'losses': {'mt': {'perplexity': True,\n",
      "                   'smoothing': 0.0,\n",
      "                   'tag': 'translation',\n",
      "                   'weight': 1},\n",
      "            'prior': {'objective': 'kl',\n",
      "                      'perplexity': False,\n",
      "                      'tag': 'prior',\n",
      "                      'tau': 2,\n",
      "                      'weight': 0.5}},\n",
      " 'model': {'decoding': {'fusion': None},\n",
      "           'dropout': 0.3,\n",
      "           'emb_renorm': False,\n",
      "           'emb_size': 512,\n",
      "           'emb_trainable': True,\n",
      "           'nhead': 8,\n",
      "           'nhid': 1024,\n",
      "           'nlayers': 6,\n",
      "           'tie_projections': True,\n",
      "           'type': 'transformer'},\n",
      " 'name': 'final.trans.ques_base',\n",
      " 'optim': {'clip': 1,\n",
      "           'early_stop': 10,\n",
      "           'eta_min': 1e-05,\n",
      "           'factor': 1,\n",
      "           'gamma': 0.5,\n",
      "           'interval': 'batch',\n",
      "           'k': 10,\n",
      "           'lr': 0.0003,\n",
      "           'milestones': [5, 15],\n",
      "           'min_lr': 1e-05,\n",
      "           'optimizer': 'adam',\n",
      "           'patience': 3,\n",
      "           'scheduler': 'noam',\n",
      "           'step_size': 1,\n",
      "           'warmup': 8000,\n",
      "           'weight_decay': 0.0},\n",
      " 'pin_memory': False,\n",
      " 'resume_cp': None,\n",
      " 'resume_state_id': None,\n",
      " 'src_dirs': ['E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\models',\n",
      "              'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\modules',\n",
      "              'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\helpers'],\n",
      " 'tag': None,\n",
      " 'transfer': {'emb': None, 'lm': None, 'tm_path': None},\n",
      " 'visdom': False}\n",
      "{'epochs': 2, 'batch_tokens': 10000, 'logging': {'log_interval': 50, 'eval_interval': 1000, 'full_eval_interval': 4000000, 'checkpoint_interval': 2, 'samples_interval': 200, 'emb_inspect_interval': 200, 'module_grad_interval': 200}, 'init': {'linear_init': 'xavier_uniform', 'lstm_hh_init': 'orthogonal', 'lstm_ih_init': 'xavier_uniform', 'embed_init': 'xavier_uniform'}, 'optim': {'optimizer': 'adam', 'lr': 0.0003, 'k': 10, 'weight_decay': 0.0, 'clip': 1, 'scheduler': 'noam', 'interval': 'batch', 'factor': 1, 'warmup': 8000, 'step_size': 1, 'patience': 3, 'eta_min': 1e-05, 'min_lr': 1e-05, 'gamma': 0.5, 'milestones': [5, 15], 'early_stop': 10}, 'data': {'src': {'train_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.train', 'val_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.dev', 'test_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\quechuaPRPE.quy.test', 'subword_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\source', 'lang': 'de'}, 'trg': {'train_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.train', 'val_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.dev', 'test_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\spanishPRPE.es.test', 'subword_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\datasets\\\\target', 'lang': 'en'}, 'seq_len': 1000, 'lowercase': True, 'sos': True, 'streaming': False, 'vocab_path': None, 'vocab_size': None, 'prior_path': 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\LlamaRoBERTa'}, 'losses': {'mt': {'weight': 1, 'tag': 'translation', 'perplexity': True, 'smoothing': 0.0}, 'prior': {'weight': 0.5, 'tag': 'prior', 'tau': 2, 'perplexity': False, 'objective': 'kl'}}, 'transfer': {'tm_path': None, 'lm': None, 'emb': None}, 'model': {'emb_renorm': False, 'type': 'transformer', 'decoding': {'fusion': None}, 'emb_trainable': True, 'emb_size': 512, 'nhid': 1024, 'nhead': 8, 'nlayers': 6, 'dropout': 0.3, 'tie_projections': True}, 'name': 'final.trans.ques_base', 'desc': None, 'config': 'configs/transformer/trans.ques_base.yaml', 'tag': None, 'visdom': False, 'pin_memory': False, 'resume_cp': None, 'resume_state_id': None, 'device': 'cpu', 'cores': 4, 'src_dirs': ['E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\models', 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\modules', 'E:\\\\Tesis\\\\Code\\\\Rimanakuy\\\\helpers']}\n",
      "Building training dataset...\n",
      "Preprocessing...\n",
      "Writing data to cache...\n",
      "Preprocessing...\n",
      "Writing data to cache...\n",
      "file                     examples    vocab    tokens (unique)  tokens (total)      max length\n",
      "---------------------  ----------  -------  -----------------  ----------------  ------------\n",
      "quechuaPRPE.quy.train      113840    38218              38215  1.8M                      1000\n",
      "spanishPRPE.es.train       113840    52000                  0  4.5M                      1000\n",
      "\n",
      "Building validation dataset...\n",
      "Preprocessing...\n",
      "Writing data to cache...\n",
      "Preprocessing...\n",
      "Writing data to cache...\n",
      "file                   examples    vocab    tokens (unique)  tokens (total)      max length\n",
      "-------------------  ----------  -------  -----------------  ----------------  ------------\n",
      "quechuaPRPE.quy.dev        2000    38218              38215  32.2K                     1000\n",
      "spanishPRPE.es.dev         2000    52000                  0  80.4K                     1000\n",
      "\n",
      "Seq2SeqTransformer(\n",
      "  (embed_src): Embed(\n",
      "    (embedding): Embedding(38218, 512, padding_idx=0)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (embed_tgt): Embed(\n",
      "    (embedding): Embedding(52000, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(num_layers=6, num_heads=8)\n",
      "  (decoder): TransformerDecoder(num_layers=6, num_heads=8)\n",
      ")\n",
      "Total Params: 77.7M\n",
      "Total Trainable Params: 77.7M\n",
      "Starting with state id:None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Tesis\\Code\\Rimanakuy\\models\\nmt_prior.py\", line 159, in <module>\n",
      "    trained_model = run(_config)\n",
      "  File \"E:\\Tesis\\Code\\Rimanakuy\\models\\nmt_prior.py\", line 138, in run\n",
      "    train_loss = trainer.train_epoch()\n",
      "  File \"E:\\Tesis\\Code\\Rimanakuy\\.\\modules\\trainer.py\", line 454, in train_epoch\n",
      "    for batch_index,batch in enumerate(self.train_loader,1):\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_io.BufferedReader' object\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"C:\\Users\\Gabriel\\anaconda3\\envs\\Rimanakuy\\lib\\multiprocessing\\spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "EOFError: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "!python models/nmt_prior.py --config configs/transformer/trans.ques_base.yaml --device cpu --name final.trans.ques_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zFQsMm1Uo3o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "sys.path.insert(0, '..')\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "from helpers.opts import exp_options\n",
    "from helpers.training import load_checkpoint\n",
    "from helpers.transfer import freeze_module\n",
    "from models.nmt_prior_callbacks import EvalCallback, SamplesCallback, \\\n",
    "    AttentionCallback\n",
    "from models.nmt_prior_helpers import nmt_dataloaders, \\\n",
    "    eval_best, backtranslate\n",
    "from models.translate import prior_model_from_checkpoint\n",
    "from models.nmt_prior_trainer import NmtPriorTrainer\n",
    "from modules.callbacks import LossCallback, GradientCallback, \\\n",
    "    ModuleGradientCallback, FunctionCallback\n",
    "from modules.data.vocab import Vocab\n",
    "from modules.initializations import model_init\n",
    "from modules.models import Seq2SeqTransformer, Seq2SeqRNN\n",
    "from sys_config import MODEL_CNF_DIR\n",
    "\n",
    "\n",
    "def run(config):\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load pretrained models\n",
    "    # -------------------------------------------------------------------------\n",
    "    vocab_src = None\n",
    "    vocab_trg = None\n",
    "\n",
    "    # Load pretrained LM, which will be used for LM-Fusion or as LM-prior\n",
    "    if config[\"data\"][\"prior_path\"] is not None:\n",
    "        if \"gpt2\" in config[\"data\"][\"prior_path\"]:\n",
    "            _gpt_model = os.path.split(config[\"data\"][\"prior_path\"])[1]\n",
    "            tokenizer = GPT2Tokenizer.from_pretrained(_gpt_model)\n",
    "            vocab_trg = Vocab()\n",
    "            vocab_trg.from_gpt2(tokenizer)\n",
    "            _checkp_prior = GPT2LMHeadModel.from_pretrained(_gpt_model)\n",
    "            config[\"model\"][\"dec_padding_idx\"] = None\n",
    "        else:\n",
    "            _checkp_prior = load_checkpoint(config[\"data\"][\"prior_path\"])\n",
    "            vocab_trg = _checkp_prior[\"vocab\"]\n",
    "\n",
    "            if _checkp_prior[\"config\"][\"data\"][\"subword_path\"] is not None:\n",
    "                sub_path = _checkp_prior[\"config\"][\"data\"][\"subword_path\"]\n",
    "                config[\"data\"][\"trg\"][\"subword_path\"] = sub_path\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Data Loading and Preprocessing\n",
    "    # -------------------------------------------------------------------------\n",
    "    train_loader, val_loader = nmt_dataloaders(config, vocab_src, vocab_trg)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Initialize Model and Priors\n",
    "    # -------------------------------------------------------------------------\n",
    "    model_type = config[\"model\"].get(\"type\", \"rnn\")\n",
    "    src_ntokens = len(val_loader.dataset.src.vocab)\n",
    "    trg_ntokens = len(val_loader.dataset.trg.vocab)\n",
    "\n",
    "    # Initialize Model\n",
    "    if model_type == \"rnn\":\n",
    "        model = Seq2SeqRNN(src_ntokens, trg_ntokens, **config[\"model\"])\n",
    "    elif model_type == \"transformer\":\n",
    "        model = Seq2SeqTransformer(src_ntokens, trg_ntokens, **config[\"model\"])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    model_init(model, **config.get(\"init\", {}))\n",
    "\n",
    "    # Initialize prior LM\n",
    "    _has_lm_prior = \"prior\" in config[\"losses\"]\n",
    "    _has_lm_fusion = config[\"model\"][\"decoding\"].get(\"fusion\") is not None\n",
    "    if _has_lm_prior or _has_lm_fusion:\n",
    "        if \"gpt2\" in config[\"data\"][\"prior_path\"]:\n",
    "            prior = _checkp_prior\n",
    "            prior.to(config[\"device\"])\n",
    "            freeze_module(prior)\n",
    "            for name, module in prior.named_modules():\n",
    "                if isinstance(module, nn.Dropout):\n",
    "                    module.p = 0\n",
    "        else:\n",
    "            prior = prior_model_from_checkpoint(_checkp_prior)\n",
    "            prior.to(config[\"device\"])\n",
    "            freeze_module(prior)\n",
    "    else:\n",
    "        prior = None\n",
    "\n",
    "    model.tie_weights()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Training Pipeline\n",
    "    # -------------------------------------------------------------------------\n",
    "    callbacks = [\n",
    "        LossCallback(config[\"logging\"][\"log_interval\"]),\n",
    "        GradientCallback(config[\"logging\"][\"log_interval\"]),\n",
    "        ModuleGradientCallback([\"encoder\"], config[\"logging\"][\"log_interval\"]),\n",
    "        SamplesCallback(config[\"logging\"][\"log_interval\"]),\n",
    "        EvalCallback(config[\"logging\"][\"eval_interval\"], keep_best=True,\n",
    "                     early_stop=config[\"optim\"][\"early_stop\"])\n",
    "    ]\n",
    "    if model_type == \"rnn\":\n",
    "        callbacks.append(AttentionCallback(config[\"logging\"][\"eval_interval\"]))\n",
    "\n",
    "    eval_interval = config[\"logging\"][\"eval_interval\"]\n",
    "    full_eval_interval = config[\"logging\"].get(\"full_eval_interval\",\n",
    "                                               15 * eval_interval)\n",
    "    callbacks.append(FunctionCallback(eval_best, full_eval_interval))\n",
    "\n",
    "    trainer = NmtPriorTrainer(model, train_loader, val_loader, config,\n",
    "                              config[\"device\"],\n",
    "                              prior=prior, callbacks=callbacks,\n",
    "                              src_dirs=config[\"src_dirs\"],\n",
    "                              resume_state_id=config[\"resume_state_id\"])\n",
    "\n",
    "    if trainer.exp.has_finished():\n",
    "        return trainer\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Training Loop\n",
    "    # -------------------------------------------------------------------------\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        train_loss = trainer.train_epoch()\n",
    "        val_loss = trainer.eval_epoch()\n",
    "        print(\"\\n\" * 3)\n",
    "\n",
    "        if trainer.early_stop:\n",
    "            print(\"Stopping early ...\")\n",
    "            break\n",
    "\n",
    "    trainer.exp.finalize()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsPMAHKjT9a4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vgojXTC5jwxh"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
